# Miscategorized commits

Welcome to the Pool of Miscategorized commits.
Add any commits that were miscategorized for your domain below.
Handle any commits that actually do belong to your domain and remove them from this list.


- [reland][ca] side-effect free inital trace: compiled_args ([#148376](https://github.com/pytorch/pytorch/pull/148376))
- unflatten isinstance ([#143664](https://github.com/pytorch/pytorch/pull/143664))
- fix torch.compile + ddp + non-reentrant AC pack hook firing count ([#144271](https://github.com/pytorch/pytorch/pull/144271))
- added `__add__` and `__mul__` hints to torch.Size ([#144322](https://github.com/pytorch/pytorch/pull/144322))
- [TorchRec][PT2] disable contextlib in PT2 train pipeline (85ea6798342)
- [ROCm] CK SDPA - Move arch check to CK patch ([#144777](https://github.com/pytorch/pytorch/pull/144777))
- [Reland][Environment Variable][4/N] Use thread-safe getenv functions ([#140593](https://github.com/pytorch/pytorch/pull/140593))
- PEP585: Missed conversions ([#145342](https://github.com/pytorch/pytorch/pull/145342))
- update _unsafe_set_version_counter to accept lists of tensors ([#137921](https://github.com/pytorch/pytorch/pull/137921))
- [BE][Ez]: ISC001 Auto concatenate implicit one line strings ([#146408](https://github.com/pytorch/pytorch/pull/146408))
- Update ck ([#144799](https://github.com/pytorch/pytorch/pull/144799))
- all reduce non strict ([#147133](https://github.com/pytorch/pytorch/pull/147133))
- more dist ops in non strict ([#147417](https://github.com/pytorch/pytorch/pull/147417))
- Fix compile errors ([#148758](https://github.com/pytorch/pytorch/pull/148758))

- Improve Pareto frontier plot for AutoAC ([#148678](https://github.com/pytorch/pytorch/pull/148678))

- Implement blend operation for float, double, int in VEC ATen backend for SVE (#146479)

- Improve KleidiAI 4 bit kernel performance (#146476)

- Use structure binding ([#144524](https://github.com/pytorch/pytorch/pull/144524))


## python_frontend
- Add warning to torch.jit.load ([#143403](https://github.com/pytorch/pytorch/pull/143403))
- Make record/storage alignment in torch.save configurable ([#147788](https://github.com/pytorch/pytorch/pull/147788))

## autograd
- Add determinmistic kernel for `reflection_pad2d_backward` ([#136241](https://github.com/pytorch/pytorch/pull/136241))
- Fix boundary conditions for hardswish backward ([#143899](https://github.com/pytorch/pytorch/pull/143899))
- [pytorch][cuda] Improve softmax backward pass native CUDA implementation ([#145866](https://github.com/pytorch/pytorch/pull/145866))
- Use float data type for Half sum in fallback implementation of batchnorm backward on CPU ([#147353](https://github.com/pytorch/pytorch/pull/147353))

## cuda
- Fix 64-bit indexing for Upsample2D on CUDA ([#141923](https://github.com/pytorch/pytorch/pull/141923))

## ROCm
- Fix torch.layer_norm invalid configuration on RoCM when input is large tensor ([#144007](https://github.com/pytorch/pytorch/pull/144007))
