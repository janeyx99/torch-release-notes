
# Release Notes worksheet inductor

The main goal of this process is to rephrase all the commit messages below to make them **clear and easy to read** by the end user. You should follow the following instructions to do so:

* **Please cleanup, and format commit titles to be readable by the general PyTorch user.** Make sure you're [following the guidance here](https://docs.google.com/document/d/14OmgGBr1w6gl1VO47GGGdwrIaUNr92DFhQbY_NEk8mQ/edit)! Your resulting notes must be consistent and easy to read.
* Please sort commits into the following categories (you should not rename the categories!), I tried to pre-sort these to ease your work, feel free to move commits around if the current categorization is not good.
* Anything that is not public facing needs to be removed.
* If anything is miscategorized/belongs to another domain, move it to `miscategorized.md`.
* Please scan through `miscategorized.md` and handle any commits that belong within your domain according to these instructions.
* Please use markdown format.
* Please use #PR_NUM to link to the PR, instead of `[#PR_NUM](https://github.com/pytorch/pytorch/pull/#PR_NUM)` to reduce the length of the release notes.
* We place a lot of emphasis on the “BC-breaking” and “deprecation” sections. Those should be where the most effort goes in. The “improvements” and “bug fixes” for Python API should be nice as well.
* Once you are finished, move this very file from `todo/` to `done/` and submit a pull request.

The categories below are as follows:

* BC breaking: All commits that are BC-breaking. These are the most important commits. If any pre-sorted commit is actually BC-breaking, do move it to this section. Each commit should contain a paragraph explaining the rational behind the change as well as an example for how to update user code [BC-Guidelines](https://docs.google.com/document/d/14OmgGBr1w6gl1VO47GGGdwrIaUNr92DFhQbY_NEk8mQ/edit#heading=h.a9htwgvvec1m).
* Deprecations: All commits introducing deprecation. Each commit should include a small example explaining what should be done to update user code.
* new_features: All commits introducing a new feature (new functions, new submodule, new supported platform etc)
* improvements: All commits providing improvements to existing feature should be here (new backend for a function, new argument, better numerical stability)
* bug fixes: All commits that fix bugs and behaviors that do not match the documentation
* performance: All commits that are added mainly for performance (we separate this from improvements above to make it easier for users to look for it)
* documentation: All commits that add/update documentation
* Developers: All commits that are not end-user facing but still impact people that compile from source, develop into pytorch, extend pytorch, etc
* not user facing: All commits that are not public end-user facing and hence should be dropped from the release notes

## inductor
### bc breaking
- [AOTI][refactor] Rename use_absolute_path to use_relative_path ([#147805](https://github.com/pytorch/pytorch/pull/147805))
### deprecation
- inductor.config.descriptive_names = False is not actually supported ([#145523](https://github.com/pytorch/pytorch/pull/145523))
### new features
- [AOTI] Emit a CMakeLists.txt when package_cpp_only ([#143352](https://github.com/pytorch/pytorch/pull/143352))
- [AOTI][reland] Emit a CMakeLists.txt when package_cpp_only ([#143680](https://github.com/pytorch/pytorch/pull/143680))
- [Inductor] Graph Partition ([#147038](https://github.com/pytorch/pytorch/pull/147038))
### improvements
- [AOTI] Relax input alignment assertion ([#143236](https://github.com/pytorch/pytorch/pull/143236))
- [AOTI] Support _int_mm ([#144571](https://github.com/pytorch/pytorch/pull/144571))
- [AOTI] Add an option to skip optimizing generated wrapper code ([#144866](https://github.com/pytorch/pytorch/pull/144866))
- Refactor fuzzer and add support for Dynamo ([#145565](https://github.com/pytorch/pytorch/pull/145565))
- [AOTI] Support composed dynamic shape constraint ([#146044](https://github.com/pytorch/pytorch/pull/146044))
- [inductor][user triton] Handle scf.yield more accurately ([#147762](https://github.com/pytorch/pytorch/pull/147762))
- [triton 3.3] cpp_wrapper: add a global_scratch arg ([#148051](https://github.com/pytorch/pytorch/pull/148051))
- Fix for AOTI + CUDAGraphs when calling from Python ([#148601](https://github.com/pytorch/pytorch/pull/148601))
### bug fixes
- [AOTI] Fix an autotune block grid computation issue ([#143098](https://github.com/pytorch/pytorch/pull/143098))
- [inductor][1/N] triton support post-#5512, main components ([#145051](https://github.com/pytorch/pytorch/pull/145051))
- [inductor][2/N] triton support post-#5512, user-defined triton kernels ([#145348](https://github.com/pytorch/pytorch/pull/145348))
- [inductor][3/N] triton support post-#5512, tt.divisibility format ([#145575](https://github.com/pytorch/pytorch/pull/145575))
- [inductor][4/N] triton support post-#5512, fix constexpr signatures ([#145583](https://github.com/pytorch/pytorch/pull/145583))
- Make sure that benchmark_harness is set before running ([#145532](https://github.com/pytorch/pytorch/pull/145532))
- Make sure not using cpp wrapper when setting nvtx training annotation ([#145538](https://github.com/pytorch/pytorch/pull/145538))
- [AOTI] Fix a memory leak in package boxed_run ([#146100](https://github.com/pytorch/pytorch/pull/146100))
- [inductor][5/N] triton support post-#5512, fix 1 and None handling ([#145515](https://github.com/pytorch/pytorch/pull/145515))
- [CPUInductor] Fix SVE256 detection ([#146207](https://github.com/pytorch/pytorch/pull/146207))
- [AOTI] Fix an unaligned memory access issue in mm_template ([#146293](https://github.com/pytorch/pytorch/pull/146293))
- fix intermediate debug information with cpp_wrapper ([#145527](https://github.com/pytorch/pytorch/pull/145527))
- [inductor] fix matmul w/ torch.bucketize epilogue ([#148769](https://github.com/pytorch/pytorch/pull/148769))
### performance
### docs
- [AOTI][doc] Update tutorial ([#143390](https://github.com/pytorch/pytorch/pull/143390))
### devs
### Untopiced
- [Reopen][Inductor][CPU] Fuse SmoothQuant int8 linear pattern ([#142036](https://github.com/pytorch/pytorch/pull/142036))
- [Inductor][CPU] Add torchao da8w8 pattern with sym quantized act & wgt ([#142110](https://github.com/pytorch/pytorch/pull/142110))
- Improve async workers to handle forking for async compile ([#142072](https://github.com/pytorch/pytorch/pull/142072))
- [inductor] Include types and size hints in MultiKernel cache key ([#142349](https://github.com/pytorch/pytorch/pull/142349))
- Backout D66648013 ([#143433](https://github.com/pytorch/pytorch/pull/143433))
- [foreach_map] Add foreach_map Adam impl to compiled optimizer tests ([#143454](https://github.com/pytorch/pytorch/pull/143454))
- [Hierarchical Compile] Update NoneAsConstantBuffer to support graph d… ([#143531](https://github.com/pytorch/pytorch/pull/143531))
- Add support for bfloat16 atomic adds in fbcode ([#143629](https://github.com/pytorch/pytorch/pull/143629))
- Support tensor subclass unwrapping ([#141941](https://github.com/pytorch/pytorch/pull/141941))
- [16/N] Fix extra warnings brought by clang-tidy-17 ([#143714](https://github.com/pytorch/pytorch/pull/143714))
- [inductor] Improve error message for assert_size_stride ([#143765](https://github.com/pytorch/pytorch/pull/143765))
- [inductor] Make adaptive_max_pool2d error on int64 ([#143762](https://github.com/pytorch/pytorch/pull/143762))
- [inductor] Shorten tracebacks for errors inside inductor (by skipping AOTAutograd frames) ([#143610](https://github.com/pytorch/pytorch/pull/143610))
- [inductor] Drop support for pre-ASTSource Triton ([#143817](https://github.com/pytorch/pytorch/pull/143817))
- [Inductor] Support tiling reduction dimensions   ([#137243](https://github.com/pytorch/pytorch/pull/137243))
- Skip L1 cache for single-use buffers ([#143115](https://github.com/pytorch/pytorch/pull/143115))
- [Inductor] [bc-breaking] Node Level provenance tracking ([#144277](https://github.com/pytorch/pytorch/pull/144277))
- Remove is_reduced_floating_point from namespace std ([#144502](https://github.com/pytorch/pytorch/pull/144502))
- Config fuzzer ([#139736](https://github.com/pytorch/pytorch/pull/139736))
- Support nanj in inductor ([#144064](https://github.com/pytorch/pytorch/pull/144064))
- [inductor] Add unbacked symints binding in ShapeProp ([#144605](https://github.com/pytorch/pytorch/pull/144605))
- [export] Fix torchbind constant folding ([#144684](https://github.com/pytorch/pytorch/pull/144684))
- [Fix]: Enable support for Arm Neon & SVE support for FP32 Gemm Wrapper ([#144327](https://github.com/pytorch/pytorch/pull/144327))
- [inductor] Fix ignored options for torch.compile ([#145131](https://github.com/pytorch/pytorch/pull/145131))
- Enable sleef for Win Arm64 ([#144876](https://github.com/pytorch/pytorch/pull/144876))
- Fix fractional_max_pool lowering in inductor ([#144395](https://github.com/pytorch/pytorch/pull/144395))
- [Customized Optimus][Inductor] Add split cat pattern in aten level ([#145721](https://github.com/pytorch/pytorch/pull/145721))
- [Inductor-CPU] Add profiling support for codegened flex attention kernels ([#145894](https://github.com/pytorch/pytorch/pull/145894))
- [Customized Optimus] Add select cat aten pass ([#145918](https://github.com/pytorch/pytorch/pull/145918))
- [inductor] Support non-power-of-2 cooperative RSPLIT ([#145689](https://github.com/pytorch/pytorch/pull/145689))
- [Optimus] Include more corner cases in the select cat aten pass ([#146662](https://github.com/pytorch/pytorch/pull/146662))
- [inductor] Fix for pattern file contains 'getitem' fails during impor… ([#144980](https://github.com/pytorch/pytorch/pull/144980))
- Turn on prologue fusion ([#147008](https://github.com/pytorch/pytorch/pull/147008))
- [Inductor] Add autotuning artifact logging ([#147222](https://github.com/pytorch/pytorch/pull/147222))
- [Cutlass] Add support for runtime param choices, starting with swizzle ([#147223](https://github.com/pytorch/pytorch/pull/147223))
- [Cutlass] Restore search space for swizzle ([#147224](https://github.com/pytorch/pytorch/pull/147224))
- [Intel GPU] qconv_pointwise.binary XPU support ([#135189](https://github.com/pytorch/pytorch/pull/135189))
- [inductor] triton support port-#5512, update cpp wrapper for gpu ([#146917](https://github.com/pytorch/pytorch/pull/146917))
- [Inductor][Optimus] Fix a corner case in split cat aten pass ([#147784](https://github.com/pytorch/pytorch/pull/147784))
- [Resubmit] Record input strides at time of tracing, constrain to them for triton fn ([#147861](https://github.com/pytorch/pytorch/pull/147861))
- [FlexAttention] Fix IMA bug ([#147918](https://github.com/pytorch/pytorch/pull/147918))
- [inductor] Implement max_pool2d_with_indices as a reduction for large window sizes ([#147876](https://github.com/pytorch/pytorch/pull/147876))
- [Inductor] optimize the heuristics of outer loop fusion ([#147523](https://github.com/pytorch/pytorch/pull/147523))
- [Inductor] Support parallel reduction for GroupNorm ([#144020](https://github.com/pytorch/pytorch/pull/144020))
- Generate AOTI input check by default ([#148005](https://github.com/pytorch/pytorch/pull/148005))
- [inductor] online softmax ([#127011](https://github.com/pytorch/pytorch/pull/127011))
- [ROCm] Incorporate ROCm triton specific tuning parameters ([#148437](https://github.com/pytorch/pytorch/pull/148437))
- [Triton 3.3] [ROCm] Enabled split_scan support for ROCm builds ([#147619](https://github.com/pytorch/pytorch/pull/147619))
- Workaround no triton float8_e8m0fnu support in inductor ([#148722](https://github.com/pytorch/pytorch/pull/148722))
- replace usages of upload_graph in inductor with tlparse (v2) ([#148720](https://github.com/pytorch/pytorch/pull/148720))
- [inductor] Fix create_specialize_impl error in latest Triton ([#148933](https://github.com/pytorch/pytorch/pull/148933))
- Support basic TorchBind in aot_compile and aoti_compile_and_package ([#148506](https://github.com/pytorch/pytorch/pull/148506))
### not user facing
- [Inductor][CPP] Fix Mask Dtype mismatch ([#142103](https://github.com/pytorch/pytorch/pull/142103))
- [FlexAttention] Fix a few more symbolic shape issues ([#142816](https://github.com/pytorch/pytorch/pull/142816))
- Fix scan dtypes ([#143048](https://github.com/pytorch/pytorch/pull/143048))
- Support remote caching requiring redis auth ([#141679](https://github.com/pytorch/pytorch/pull/141679))
- [Inductor] Refactor "r" reduction prefix to {"r0_", "r1_"}. ([#142020](https://github.com/pytorch/pytorch/pull/142020))
- [Inductor] Fix cooperative reduction tests broken in recent refactor ([#143135](https://github.com/pytorch/pytorch/pull/143135))
- [inductor] Replace set by OrderedSet ([#138466](https://github.com/pytorch/pytorch/pull/138466))
- Add "inductor_pre_grad_graph" logging (#142717) ([#143126](https://github.com/pytorch/pytorch/pull/143126))
- [Inductor] Move peak memory pass and overlap pass to be run at the right place ([#142822](https://github.com/pytorch/pytorch/pull/142822))
- [FlexAttention] Optimzing learned bias perf to dq calc ([#142281](https://github.com/pytorch/pytorch/pull/142281))
- [Inductor] Fix the Index Put lowering with same input of self and values ([#139366](https://github.com/pytorch/pytorch/pull/139366))
- Add persistent+TMA version of Triton mm and addmm ([#142101](https://github.com/pytorch/pytorch/pull/142101))
- [Inductor][Easy] Fix a test failure in loop_ordering_after_fusion ([#142474](https://github.com/pytorch/pytorch/pull/142474))
- [FlexAttention] Allow num_warps 8 since when block size >=128 ([#143299](https://github.com/pytorch/pytorch/pull/143299))
- remove allow-untyped-defs for _inductor/codegen/rocm/rocm_template_buffer.py ([#143272](https://github.com/pytorch/pytorch/pull/143272))
- [user triton cache] Dedup user-defined Triton kernels by config in codecache ([#143353](https://github.com/pytorch/pytorch/pull/143353))
- [inductor] invalidate pointwise dep cache for LOAF ([#141160](https://github.com/pytorch/pytorch/pull/141160))
- cpp_builder: handle CUDA lib paths involving "stubs" in more circumstances ([#142175](https://github.com/pytorch/pytorch/pull/142175))
- remove nonowninglayout special case in require strides ([#143315](https://github.com/pytorch/pytorch/pull/143315))
- Fix non-dense inductor effn attn bias ([#141905](https://github.com/pytorch/pytorch/pull/141905))
- Add flex attention kernel parameter tuning options ([#139639](https://github.com/pytorch/pytorch/pull/139639))
- Use process pool for precompilation of triton templates ([#142450](https://github.com/pytorch/pytorch/pull/142450))
- [provenance_tracking] Dump inductor_triton_kernel_to_post_grad_nodes.json info in debug_trace ([#143055](https://github.com/pytorch/pytorch/pull/143055))
- remove allow-untyped-defs for torch/_inductor/test_operators.py ([#143436](https://github.com/pytorch/pytorch/pull/143436))
- [AOTI] Refactor path operations in AotCodeCompiler ([#143350](https://github.com/pytorch/pytorch/pull/143350))
- [AOTI] Fix a typo in cpp_builder.py ([#143351](https://github.com/pytorch/pytorch/pull/143351))
- [Inductor] move custom pre pass ([#143458](https://github.com/pytorch/pytorch/pull/143458))
- [Inductor][CPU] disable bernoulli_p decomposition ([#143460](https://github.com/pytorch/pytorch/pull/143460))
- [Inductor][CPP] Fix bitwise shift with corner inputs ([#143635](https://github.com/pytorch/pytorch/pull/143635))
- Make Inductor cpp backend enable_floating_point_contract_flag to take string ([#143450](https://github.com/pytorch/pytorch/pull/143450))
- [inductor] Fix an unused variable in cpu_vec_isa.py ([#138473](https://github.com/pytorch/pytorch/pull/138473))
- [Inductor XPU] Add XPU check for `is_big_gpu()`. ([#143491](https://github.com/pytorch/pytorch/pull/143491))
- [AOTI XPU] Replace intel compiler with g++ to build inductor CPP wrapper in runtime. ([#142322](https://github.com/pytorch/pytorch/pull/142322))
- Reuse partial reductions ([#143600](https://github.com/pytorch/pytorch/pull/143600))
- Remove unused <ATen/core/Array.h> inclusion ([#143701](https://github.com/pytorch/pytorch/pull/143701))
- [BE] Update triton repo link ([#143429](https://github.com/pytorch/pytorch/pull/143429))
- Inductor Cutlass backend: Eliminate unused code. ([#143723](https://github.com/pytorch/pytorch/pull/143723))
- [inductor] Fix for extract_target with dots ([#143766](https://github.com/pytorch/pytorch/pull/143766))
- [inductor] fix the `adaptive_avg_pool` on processing int64 ([#143802](https://github.com/pytorch/pytorch/pull/143802))
- [inductor] Reorder imports in codecache.py ([#143813](https://github.com/pytorch/pytorch/pull/143813))
- [inductor] Refactor conditional triton imports into triton_compat.py ([#143814](https://github.com/pytorch/pytorch/pull/143814))
- [inductor] Minor refactor of hip compile_meta ([#143815](https://github.com/pytorch/pytorch/pull/143815))
- [inductor] Move GPUTarget backwards compat to triton_compat.py ([#143818](https://github.com/pytorch/pytorch/pull/143818))
- [inductor] Simplify get_launch_args_* handling ([#143835](https://github.com/pytorch/pytorch/pull/143835))
- remove allow-untyped-defs from _inductor/codegen/cpu_device_op_overrides.py ([#143881](https://github.com/pytorch/pytorch/pull/143881))
- [inductor][invoke_subgraph] Support None/int as input/output of invoke_subgraph ([#139373](https://github.com/pytorch/pytorch/pull/139373))
- remove allow-untyped-defs from _inductor/codegen/aoti_hipify_utils.py ([#143916](https://github.com/pytorch/pytorch/pull/143916))
- remove allow-untyped-defs from _inductor/codegen/rocm/rocm_template_buffer.py ([#143870](https://github.com/pytorch/pytorch/pull/143870))
- [CUTLASS] fix bugs: extra data_ptr() call, wrong size symbol name, bias symbol not added ([#143528](https://github.com/pytorch/pytorch/pull/143528))
- [CUTLASS] fix addmm ([#143537](https://github.com/pytorch/pytorch/pull/143537))
- Fix emulate low precision bool inp ([#143657](https://github.com/pytorch/pytorch/pull/143657))
- Fix separate in process bisector cache, cleanup on exit ([#143661](https://github.com/pytorch/pytorch/pull/143661))
- [Inductor][CPP] Fix Data Type issue of frexp ([#143746](https://github.com/pytorch/pytorch/pull/143746))
- remove allow-untyped-defs from _inductor/compile_worker/watchdog.py ([#143941](https://github.com/pytorch/pytorch/pull/143941))
- cpp_wrapper: minimize pybind11 dependency ([#143772](https://github.com/pytorch/pytorch/pull/143772))
- [Inductor] Relax size constraints for re-inplacing ([#143884](https://github.com/pytorch/pytorch/pull/143884))
- [AOTI] Not use AOTI_TORCH_CHECK in non AOTI mode. ([#143970](https://github.com/pytorch/pytorch/pull/143970))
- [inductor] Add missing py312 xfail ([#144006](https://github.com/pytorch/pytorch/pull/144006))
- [Inductor][CPU] Fix C++ compile error of torch.max on bool type ([#143848](https://github.com/pytorch/pytorch/pull/143848))
- [AOTI] don't codegen autotune_at_compile_time for non-Triton kernels ([#143990](https://github.com/pytorch/pytorch/pull/143990))
- [Inductor] Generalize tiling algorithm to handle fused reductions ([#144041](https://github.com/pytorch/pytorch/pull/144041))
- [Inductor] Fix `torch.polygamma()` when n == 0 ([#144058](https://github.com/pytorch/pytorch/pull/144058))
- [Inductor/Triton] Upcast FP16/BF16 math reductions to FP32 ([#141052](https://github.com/pytorch/pytorch/pull/141052))
- [Inductor][lowering] support out_dtype for dequant lowering ([#143845](https://github.com/pytorch/pytorch/pull/143845))
- [inductor] Add types to compile_tasks.py and runtime_utils.py ([#144004](https://github.com/pytorch/pytorch/pull/144004))
- [Inductor][CPP] Fix Inductor integer avg pool ([#144059](https://github.com/pytorch/pytorch/pull/144059))
- [inductor] Avoid specializing over symbolic value during constant folding ([#144176](https://github.com/pytorch/pytorch/pull/144176))
- [EZ][BE] Fix E226 flake8 violation ([#144282](https://github.com/pytorch/pytorch/pull/144282))
- [Inductor][CPP] Fix outer loop fusion buffer removed ([#144243](https://github.com/pytorch/pytorch/pull/144243))
- Migrate from Tuple -> tuple in torch/_inductor ([#144264](https://github.com/pytorch/pytorch/pull/144264))
- [Quant][Inductor][X86] Separate unary post op fusion and lowering for qlinear ([#143903](https://github.com/pytorch/pytorch/pull/143903))
- [Inductor] Add convolution output size checking to the meta function ([#144225](https://github.com/pytorch/pytorch/pull/144225))
- feature_use: Remove JK from naming for feature use. ([#143529](https://github.com/pytorch/pytorch/pull/143529))
- Add instantiation level to CutlassArgs ([#144506](https://github.com/pytorch/pytorch/pull/144506))
- [Intel GPU][Inductor] Convert Conv1D to 2D in inductor ([#144140](https://github.com/pytorch/pytorch/pull/144140))
- [ROCm][Inductor][CK] hackfix for segfault in addmm op ([#144519](https://github.com/pytorch/pytorch/pull/144519))
- [Inductor] Restrict ND tiling analysis to MemoryDeps ([#144497](https://github.com/pytorch/pytorch/pull/144497))
- Disable scuba logging for autotuning ([#144568](https://github.com/pytorch/pytorch/pull/144568))
- [Inductor][CPP] Enable Grouped GEMM Template ([#143796](https://github.com/pytorch/pytorch/pull/143796))
- [Inductor][CPP] Enable Epilogue Fusion for Grouped GEMM Template ([#143897](https://github.com/pytorch/pytorch/pull/143897))
- [inductor][triton] skip test_data_type_propagation if triton ([#142054](https://github.com/pytorch/pytorch/pull/142054))
- [cutlass backend] cexpr the arg before writing to cpp file ([#144714](https://github.com/pytorch/pytorch/pull/144714))
- [Quant][Inductor][X86] Separate unary post op fusion and lowering for qconv ([#144312](https://github.com/pytorch/pytorch/pull/144312))
- Restore support for other types of async_compile pools (spawn, fork) ([#144491](https://github.com/pytorch/pytorch/pull/144491))
- [inductor][BE] don't try/except ImportError for AttrsDescriptor versions ([#144807](https://github.com/pytorch/pytorch/pull/144807))
- [Quant][Inductor][X86] Separate binary post op fusion and lowering for qconv ([#144318](https://github.com/pytorch/pytorch/pull/144318))
- [inductor] fix index.Tensor fallback ([#144736](https://github.com/pytorch/pytorch/pull/144736))
- [aoti] Deduplicate "V.aot_compilation" and "V.graph.aot_mode" flags. [1/n] ([#144709](https://github.com/pytorch/pytorch/pull/144709))
- [Inductor][FlexAttention] Supports dynamic shapes with custom kernel options ([#144938](https://github.com/pytorch/pytorch/pull/144938))
- Add heuristic to fail block pointer match early ([#144681](https://github.com/pytorch/pytorch/pull/144681))
- [inductor] [bug fix] align `avg_pool` with eager when handling `uint` ([#144313](https://github.com/pytorch/pytorch/pull/144313))
- Fuzzer Improvements ([#144952](https://github.com/pytorch/pytorch/pull/144952))
- Adding more compile time logging in pad_mm ([#144884](https://github.com/pytorch/pytorch/pull/144884))
- [inductor] fix TORCH_LOGS="benchmarking" ([#144997](https://github.com/pytorch/pytorch/pull/144997))
- fix test_rng bisector test ([#143662](https://github.com/pytorch/pytorch/pull/143662))
- [inductor] Refactor CachingAutotuner so that it can pickle ([#144044](https://github.com/pytorch/pytorch/pull/144044))
- PEP585 update - torch/_inductor/fx_passes ([#145107](https://github.com/pytorch/pytorch/pull/145107))
- refactor benchmarking to use dynamo_timed ([#144315](https://github.com/pytorch/pytorch/pull/144315))
- basic InductorBenchmarker ([#133058](https://github.com/pytorch/pytorch/pull/133058))
- [aoti] Remove torch.ops.aten._assert_tensor_metadata.default in post_grad_pass ([#145028](https://github.com/pytorch/pytorch/pull/145028))
- PEP585 update - torch/_inductor/codegen ([#145106](https://github.com/pytorch/pytorch/pull/145106))
- PEP585 update - torch/_inductor/[_-i]* ([#145137](https://github.com/pytorch/pytorch/pull/145137))
- [aoti] Deduplicate "V.aot_compilation" and "V.graph.aot_mode" flags. [2/n] ([#145091](https://github.com/pytorch/pytorch/pull/145091))
- [inductor] fix MA on poor gpu ([#145133](https://github.com/pytorch/pytorch/pull/145133))
- [inductor] Simplify mode options, only apply CompilerBisector changes once ([#145232](https://github.com/pytorch/pytorch/pull/145232))
- PEP585 update - torch/_inductor ([#145198](https://github.com/pytorch/pytorch/pull/145198))
- [Inductor][CPU] Add auto-tuning support for da8w8 sym act sym wgt GEMM ([#143187](https://github.com/pytorch/pytorch/pull/143187))
- [BE] Add type annotations to cudagraph_utils.py and test_cases.py ([#145291](https://github.com/pytorch/pytorch/pull/145291))
- [Test][Inductor] Fix test_tma_graph_breaks ([#145271](https://github.com/pytorch/pytorch/pull/145271))
- [inductor] let inplace-padding support cpp-wrapper ([#145325](https://github.com/pytorch/pytorch/pull/145325))
- [inductor] fix autotuning memory usage ([#145410](https://github.com/pytorch/pytorch/pull/145410))
- Enable non power of 2 head_dim for FlexAttention ([#133495](https://github.com/pytorch/pytorch/pull/133495))
- [BE] Type annotate metrics.py ([#145418](https://github.com/pytorch/pytorch/pull/145418))
- [BE] Type annotate pad_mm.py ([#145409](https://github.com/pytorch/pytorch/pull/145409))
- Implement deepcopy for AOTICompiledModel ([#145423](https://github.com/pytorch/pytorch/pull/145423))
- Bail on checking internal overlap when dealing with unbacked symints ([#145385](https://github.com/pytorch/pytorch/pull/145385))
- Inductor cache: Revamp how we handle frozen params ([#143808](https://github.com/pytorch/pytorch/pull/143808))
- cpp_wrapper: Properly handle scalars when input to tensor arguments ([#144910](https://github.com/pytorch/pytorch/pull/144910))
- Don't fail if fresh_inductor_cache fails to clean up its tmp dir. ([#145513](https://github.com/pytorch/pytorch/pull/145513))
- [BE] Type annotation for `_inductor/dependencies.py` ([#145311](https://github.com/pytorch/pytorch/pull/145311))
- Add unique identifer to bmm thread_mm functions ([#145303](https://github.com/pytorch/pytorch/pull/145303))
- [Inductor] be able to disable cache for test ([#141195](https://github.com/pytorch/pytorch/pull/141195))
- Spruce up docs for emulate_precision_casts ([#145579](https://github.com/pytorch/pytorch/pull/145579))
- [inductor] Kernel memory analysis for use in heuristics ([#142026](https://github.com/pytorch/pytorch/pull/142026))
- [inductor] Fix duplicate detection in _dynamic_scale_rblock ([#145577](https://github.com/pytorch/pytorch/pull/145577))
- [Rocm][Inductor][CK] silence ck package not installed warning when CK backend is not used to autotune bmm ([#145626](https://github.com/pytorch/pytorch/pull/145626))
- [inductor] Adjust test_log_fp64 to only run when float64 is supported. ([#145686](https://github.com/pytorch/pytorch/pull/145686))
- [inductor] Add some typing to simd.py ([#145690](https://github.com/pytorch/pytorch/pull/145690))
- [inductor] Add some typing to common.py ([#145691](https://github.com/pytorch/pytorch/pull/145691))
- simplify torch.utils.cpp_extension.include_paths; use it in cpp_builder ([#145480](https://github.com/pytorch/pytorch/pull/145480))
- [Inductor][CPP] fix torch logit decomposition ([#145576](https://github.com/pytorch/pytorch/pull/145576))
- [inductor] Change type of get_backend_features to OrderedSet ([#145692](https://github.com/pytorch/pytorch/pull/145692))
- [inductor] Remove type ignores from scheduler.py ([#145712](https://github.com/pytorch/pytorch/pull/145712))
- [BE][Inductor] Simplify `custom_op` tests ([#145814](https://github.com/pytorch/pytorch/pull/145814))
- [inductor] Fix crash running wrapper_benchmark with no device ([#145644](https://github.com/pytorch/pytorch/pull/145644))
- fix unbacked + view incorrectness ([#145548](https://github.com/pytorch/pytorch/pull/145548))
- Parallelize epilogue/prologue benchmarking ([#143408](https://github.com/pytorch/pytorch/pull/143408))
- Maintain multiple configs ([#145103](https://github.com/pytorch/pytorch/pull/145103))
- [aotinductor] update unbacked symint runtime assertion msg ([#145569](https://github.com/pytorch/pytorch/pull/145569))
- [Inductor][Triton] Change propagated dtype for fp16/bf16 unwrapped 0d tensors ([#145613](https://github.com/pytorch/pytorch/pull/145613))
- [inductor] Make triton kernel autotune config defaults backward-compatible ([#145494](https://github.com/pytorch/pytorch/pull/145494))
- Fix lowering to inductor IR for triton CPU ([#144389](https://github.com/pytorch/pytorch/pull/144389))
- Fix a number of flexattention issues (cse, cudagraph, etc.) ([#145059](https://github.com/pytorch/pytorch/pull/145059))
- [inductor] Fix handling of fixed XBLOCK larger than xnumel=1 ([#145671](https://github.com/pytorch/pytorch/pull/145671))
- [inductor] Remove mask_str from IndexingOptions ([#145695](https://github.com/pytorch/pytorch/pull/145695))
- [inductor] Add some typing to triton.py ([#145688](https://github.com/pytorch/pytorch/pull/145688))
- give emulate_precision_casts an envar ([#145948](https://github.com/pytorch/pytorch/pull/145948))
- [BE] Type annotate wrapper_benchmark.py and cuda_combined_scheduling.py ([#145542](https://github.com/pytorch/pytorch/pull/145542))
- add inductor_triton_kernel_mapping_post_grad.json to tlparseadd changes ([#145954](https://github.com/pytorch/pytorch/pull/145954))
- Fix signif_strides_equal for symints, dedupe ([#145953](https://github.com/pytorch/pytorch/pull/145953))
- [AOTI] Remove AOTI_USE_CREATE_TENSOR_FROM_BLOB_V1 ([#146039](https://github.com/pytorch/pytorch/pull/146039))
- Fix code cache + freezing compile-time regression ([#145868](https://github.com/pytorch/pytorch/pull/145868))
- [AOTI] Refactor codegen_input_symbol_assignment ([#146043](https://github.com/pytorch/pytorch/pull/146043))
- Cap size of thread pool in select_algorithm to cpu count ([#146071](https://github.com/pytorch/pytorch/pull/146071))
- Adding the best autotuner config ([#146121](https://github.com/pytorch/pytorch/pull/146121))
- [inductor] Add types to DeviceOpOverrides ([#145913](https://github.com/pytorch/pytorch/pull/145913))
- [inductor] Combine regexp checks in OpOverrides.paren ([#145914](https://github.com/pytorch/pytorch/pull/145914))
- [inductor] Add typing to common.OpDecompositions ([#145915](https://github.com/pytorch/pytorch/pull/145915))
- [inductor] Guard a member variable with a define. ([#146278](https://github.com/pytorch/pytorch/pull/146278))
- [cutlass backend] update try_import_cutlass to accomodate for pip install ([#145891](https://github.com/pytorch/pytorch/pull/145891))
- [easy] Add type annotation for autotune_num_choices_displayed ([#146323](https://github.com/pytorch/pytorch/pull/146323))
- [cutlass backend] Add instantiation level for generating configs ([#146230](https://github.com/pytorch/pytorch/pull/146230))
- cpp_wrapper/aot_inductor: handle conjugation and negation dispatch keys ([#145095](https://github.com/pytorch/pytorch/pull/145095))
- Make the CUTLASS swizzle options configurable and default to 2. ([#146088](https://github.com/pytorch/pytorch/pull/146088))
- [cpp_builder] refactor to reduce libcudart_static logs ([#146394](https://github.com/pytorch/pytorch/pull/146394))
- [auto_functionalized] Support `Tensor(a!)[]?` ([#145400](https://github.com/pytorch/pytorch/pull/145400))
- [Inductor] Add a JIT Inductor unit test following #146293 ([#146529](https://github.com/pytorch/pytorch/pull/146529))
- [inductor] Fix test error test_force_cutlass_backend_aoti_cexpr_codegen ([#146564](https://github.com/pytorch/pytorch/pull/146564))
- Expand inductor codegen dtype asserts, fix scan ([#146067](https://github.com/pytorch/pytorch/pull/146067))
- Check meta strides for expanded dims in effn_attn_bias ([#146054](https://github.com/pytorch/pytorch/pull/146054))
- fuzzer: disable "fail_on_recompile_limit_hit" and "suppress_errors" ([#146650](https://github.com/pytorch/pytorch/pull/146650))
- [inductor] add size-asserts for fallback ops ([#145904](https://github.com/pytorch/pytorch/pull/145904))
- [inductor] Use index_dtype (int32/int64 depending on size) for argmax accumulators ([#146651](https://github.com/pytorch/pytorch/pull/146651))
- [inductor] Better exception error messages for cache_on_self ([#146652](https://github.com/pytorch/pytorch/pull/146652))
- [FlexAttention] Fix dynamic shapes in max-autotune ([#146657](https://github.com/pytorch/pytorch/pull/146657))
- Fix assertion failure in gemm template lowering ([#146353](https://github.com/pytorch/pytorch/pull/146353))
- [Inductor] Expand Identity ops prior to block pattern matching ([#146000](https://github.com/pytorch/pytorch/pull/146000))
- futher scheduler changes for invoke_quant: prologue low prec, (slightly) more aggressive fusion ([#145104](https://github.com/pytorch/pytorch/pull/145104))
- [ez][BE] get rid of the extra printf('\n') ([#146726](https://github.com/pytorch/pytorch/pull/146726))
- use None to slice when list has one element only ([#146638](https://github.com/pytorch/pytorch/pull/146638))
- Make sure cutlass kernel .cu file has configuration name and nvcc compile command ([#146668](https://github.com/pytorch/pytorch/pull/146668))
- Optimize inductor `Self` typing ([#146669](https://github.com/pytorch/pytorch/pull/146669))
- [hop][inductor] don't promote arg type for cond and while_loop ([#146660](https://github.com/pytorch/pytorch/pull/146660))
- [cutlass backend] check against arch >= 100 ([#145812](https://github.com/pytorch/pytorch/pull/145812))
- [inductor] Remove _get_grid_fn_str ([#146800](https://github.com/pytorch/pytorch/pull/146800))
- Only call triton in worker process, kick off worker processes earlier, during inductor codegen ([#146417](https://github.com/pytorch/pytorch/pull/146417))
- [FlexAttention] Bug fix broken flag ([#146872](https://github.com/pytorch/pytorch/pull/146872))
- [Inductor] Unifiy Low Precision FP Legalization for to_dtype_bitcast & constant ([#144646](https://github.com/pytorch/pytorch/pull/144646))
- [inductor] skip _test_insignificant_strides on rocm ([#146849](https://github.com/pytorch/pytorch/pull/146849))
- Clear CompiledTritonKernel cache after each inductor compile ([#146925](https://github.com/pytorch/pytorch/pull/146925))
- Fix CUTLASS 2.x kernels for auto-tuning ([#146755](https://github.com/pytorch/pytorch/pull/146755))
- Fix standalone runner for CUTLASS auto-tuning backend ([#146764](https://github.com/pytorch/pytorch/pull/146764))
- [FlexAttention] Make zero_length sequence handiling better ([#147010](https://github.com/pytorch/pytorch/pull/147010))
- [docs] Minor fixes to export and aoti docs ([#144513](https://github.com/pytorch/pytorch/pull/144513))
- [inductor][refactor] Make _compile_file only used for fbcode ([#147106](https://github.com/pytorch/pytorch/pull/147106))
- [Inductor][CPP] Fix a CPP GEMM Template output data type issue ([#146958](https://github.com/pytorch/pytorch/pull/146958))
- torch: Log a unified waitcounter for torch.compile and triton.autotune ([#146723](https://github.com/pytorch/pytorch/pull/146723))
- [inductor] [cpp] Support vectorization for score and mask in FlexAttention CPU ([#143638](https://github.com/pytorch/pytorch/pull/143638))
- [Inductor][CPP] Fix node name for wgt delete ([#147056](https://github.com/pytorch/pytorch/pull/147056))
- try print stacktrace for error ([#147061](https://github.com/pytorch/pytorch/pull/147061))
- [inductor][refactor] Move _compile_file to cpp_builder ([#147202](https://github.com/pytorch/pytorch/pull/147202))
- [Inductor] Fix the lowering of squeeze when input is not contiguous ([#146746](https://github.com/pytorch/pytorch/pull/146746))
- [inductor] Don't leak pointers to cpp_wrapper with lru_cache ([#147233](https://github.com/pytorch/pytorch/pull/147233))
- [Inductor] Fix Inplace Buffer inner name conflict ([#147199](https://github.com/pytorch/pytorch/pull/147199))
- [inductor] Add type annotations to _inductor/utils.py  ([#144108](https://github.com/pytorch/pytorch/pull/144108))
- [Inductor] Fix 3D tiling with permute ([#147249](https://github.com/pytorch/pytorch/pull/147249))
- [Inductor][CPP] Add the legalize low fp support for index expr ([#147298](https://github.com/pytorch/pytorch/pull/147298))
- Fix the AOTI compile failure with ARM CPU for Meta internal ([#147204](https://github.com/pytorch/pytorch/pull/147204))
- [codegen] enable SORT and TUPLE_REDUCTION for AMD Triton ([#147340](https://github.com/pytorch/pytorch/pull/147340))
- More precise check for shared storage check in inductor/reinplace pass ([#147050](https://github.com/pytorch/pytorch/pull/147050))
- [Sigmoid] Fix issues with constant folding and fba_ops ([#146948](https://github.com/pytorch/pytorch/pull/146948))
- Revert "[ROCm] ROCm-specific gemm tuning parameters" ([#147388](https://github.com/pytorch/pytorch/pull/147388))
- [inductor] Freeze runtime asserts after shape prop but before codegen ([#147331](https://github.com/pytorch/pytorch/pull/147331))
- [FlexAttention] Fix weird generate stride call in flex decode ([#147435](https://github.com/pytorch/pytorch/pull/147435))
- [inductor] GraphLowering code movement ([#147335](https://github.com/pytorch/pytorch/pull/147335))
- [BE] remove  sysconfig.get_config_var("LIBDIR") from cuda lib paths ([#147409](https://github.com/pytorch/pytorch/pull/147409))
- Add type hints to cuda kernel ([#147471](https://github.com/pytorch/pytorch/pull/147471))
- [reland][cutlass backend] Do not change dtype of GEMM template for cutlass 3x ([#147434](https://github.com/pytorch/pytorch/pull/147434))
- Move ir_pre_fusion.txt and ir_post_fusion.txt to TORCH_LOGS ([#147248](https://github.com/pytorch/pytorch/pull/147248))
- [Cutlass] Add test verifying number of precompiles ([#147477](https://github.com/pytorch/pytorch/pull/147477))
- Fix RuntimeError: value cannot be converted to type int64_t without overflow ([#147492](https://github.com/pytorch/pytorch/pull/147492))
- Make Inductor scheduler aware of _scaled_mm ([#146992](https://github.com/pytorch/pytorch/pull/146992))
- Optimize `graph.py` typing ([#147099](https://github.com/pytorch/pytorch/pull/147099))
- Add current cuda device index to FXGraphCache key ([#147464](https://github.com/pytorch/pytorch/pull/147464))
- [ROCm] Update meta_registration for efficient attention ([#146979](https://github.com/pytorch/pytorch/pull/146979))
- Use has_triton_package in _inductor.runtime.hints ([#147442](https://github.com/pytorch/pytorch/pull/147442))
- [cutlass backend] Fix standalone runner test after swizzle became a runtime parameter ([#147554](https://github.com/pytorch/pytorch/pull/147554))
- For addmm and bmm, check if config.autotune_fallback_to_aten before using aten as a fallback. Also fix bmm cutlass backend  ([#147148](https://github.com/pytorch/pytorch/pull/147148))
- [ROCm] gfx940 and gfx941 cleanup ([#147394](https://github.com/pytorch/pytorch/pull/147394))
- [cutlass backend] clear_on_fresh_inductor_cache when generatings cutlass ops ([#147586](https://github.com/pytorch/pytorch/pull/147586))
- [inductor][cpu] Move VNNI weight packing into AMX GEMM kernel for contiguous BMM weights ([#146843](https://github.com/pytorch/pytorch/pull/146843))
- [Inductor UT][Windows][XPU] Fix Inductor UT on XPU Windows. ([#146481](https://github.com/pytorch/pytorch/pull/146481))
- [Inductor] Update should_decompose_mm condition for CPU ([#147673](https://github.com/pytorch/pytorch/pull/147673))
- [AOTI][XPU] Suppress multi-line comment warning for XPU. ([#147710](https://github.com/pytorch/pytorch/pull/147710))
- [Inductor] Hot fix after #146917 ([#147639](https://github.com/pytorch/pytorch/pull/147639))
- [Inductor] Update `set_driver_to_gpu` code to avoid backend re-initialization with new Triton ([#147621](https://github.com/pytorch/pytorch/pull/147621))
- [Inductor] Fix the decompositions of torch isin ([#147519](https://github.com/pytorch/pytorch/pull/147519))
- [Inductor] Add input value checking to randint meta function ([#147191](https://github.com/pytorch/pytorch/pull/147191))
- cpp_builder: unbreak clang++ detection ([#147775](https://github.com/pytorch/pytorch/pull/147775))
- Fix import of getArtifactLogger for ir_pre_fusion and ir_post_fusion ([#147560](https://github.com/pytorch/pytorch/pull/147560))
- [Inductor][ROCm][CK] Unhardedcoded kernel shapes for ck_conv_template codegen ([#147504](https://github.com/pytorch/pytorch/pull/147504))
- [AOTI][refactor] Replace run_command_and_check with CppBuilder.build ([#147806](https://github.com/pytorch/pytorch/pull/147806))
- [AOTI][refactor] Fix a typo ([#147807](https://github.com/pytorch/pytorch/pull/147807))
- [logging] Add toplevel dynamo_compile / tlparse logging for AOTI ([#147760](https://github.com/pytorch/pytorch/pull/147760))
- cpp_wrapper: fix inductor triton tests ([#146109](https://github.com/pytorch/pytorch/pull/146109))
- cpp_wrapper: Fixup output code indentation ([#147215](https://github.com/pytorch/pytorch/pull/147215))
- [custom op] fix inductor cpp codegen when returning a list of single tensor ([#147649](https://github.com/pytorch/pytorch/pull/147649))
- [Inductor][Tests] Update `get_divisible_by_16` function in `test_torchinductor.py` to work correctly with new Triton ([#147865](https://github.com/pytorch/pytorch/pull/147865))
- [inductor][ck] kBatch parametrized ([#147885](https://github.com/pytorch/pytorch/pull/147885))
- [Inductor][CPP] fix store mode atomic add ([#147961](https://github.com/pytorch/pytorch/pull/147961))
- [FlexAttention] Improve error msg for embedding < 16 ([#147765](https://github.com/pytorch/pytorch/pull/147765))
- [inductor] Add logs for precompile and autotuning ([#147923](https://github.com/pytorch/pytorch/pull/147923))
- [PT2] Support add/remove passes in pre_grad ([#146064](https://github.com/pytorch/pytorch/pull/146064))
- [cutlass backend] turn autotuning logs off by default + rename log to autotuning log ([#147922](https://github.com/pytorch/pytorch/pull/147922))
- [AOTI][refactor] Consolidate CppBuilder.build and CppBuilder.build_fbcode ([#147975](https://github.com/pytorch/pytorch/pull/147975))
- [cutlass backend] cache_clear algorithm select cache on fresh inductor cache ([#147590](https://github.com/pytorch/pytorch/pull/147590))
- [Inductor] Use generic GPU device in test_preserves_strides ([#148006](https://github.com/pytorch/pytorch/pull/148006))
- Add unique kernel name support for user defined triton kernel ([#147587](https://github.com/pytorch/pytorch/pull/147587))
- Skip the logging if the pass cannot be pickled ([#148053](https://github.com/pytorch/pytorch/pull/148053))
- [Inductor] Fix `inductor/test_kernel_benchmark.py` for new Triton; do not duplicate parameters in `_dump_launch_params` ([#147746](https://github.com/pytorch/pytorch/pull/147746))
- [inductor][ck] kBatch filtering with gen_ops ([#148004](https://github.com/pytorch/pytorch/pull/148004))
- [PT2] Port fuse_split_getitem_squeeze to PT2 pre_grad passes ([#148059](https://github.com/pytorch/pytorch/pull/148059))
- Move expanded dim require_exact_stride handling to api from sdpa lowering ([#148101](https://github.com/pytorch/pytorch/pull/148101))
- [triton 3.3] Fix aoti cpp wrapper remaining 5 issue. (following #148051) ([#148117](https://github.com/pytorch/pytorch/pull/148117))
- [BE][PYFMT] migrate PYFMT for `torch._inductor` to `ruff format` ([#144550](https://github.com/pytorch/pytorch/pull/144550))
- [cutlass backend] Check if len(timings) == len(choices) before skipping precompile ([#148050](https://github.com/pytorch/pytorch/pull/148050))
- [cutlass backend] Sort the list of ops for better repro ([#148047](https://github.com/pytorch/pytorch/pull/148047))
- [cond] support mismatched output in inductor ([#147567](https://github.com/pytorch/pytorch/pull/147567))
- [while_loop][inductor] relax the constraint that all inputs must be on the same device ([#148019](https://github.com/pytorch/pytorch/pull/148019))
- [Inductor-CPU] Fix broken int8 WoQ GEMM AMX implementation in main ([#147895](https://github.com/pytorch/pytorch/pull/147895))
- [inductor][cutlass] Environment variables for allow/denylist ([#148161](https://github.com/pytorch/pytorch/pull/148161))
- [inductor][ck] manual kBatch heuristic ([#148118](https://github.com/pytorch/pytorch/pull/148118))
- [inductor] ignore block ptr advancements for removed buffers ([#148087](https://github.com/pytorch/pytorch/pull/148087))
- [Inductor] fix `AOTInductorTestABICompatibleGpu.test_triton_kernel_weird_param_order` with new Triton ([#148011](https://github.com/pytorch/pytorch/pull/148011))
- [Inductor][NFC] Remove unused functions from `compile_tasks.py` ([#147564](https://github.com/pytorch/pytorch/pull/147564))
- [inductor][subgraph] Plumbing to get ShapeAsConstantBuffer from subgraph to main graph output ([#147559](https://github.com/pytorch/pytorch/pull/147559))
- [Break XPU][Inductor] Generalize device-bias code and fix test_graph_partition for XPU ([#148178](https://github.com/pytorch/pytorch/pull/148178))
- Fix None and equal_to_1 arguments issue in Triton kernel generated by AOTI ([#148102](https://github.com/pytorch/pytorch/pull/148102))
- [aotinductor] add option to disable runtime assertions ([#146462](https://github.com/pytorch/pytorch/pull/146462))
- [Inductor][CPU] Add GEMM templates for _weight_int4pack_mm_for_cpu with AVX512 ([#146756](https://github.com/pytorch/pytorch/pull/146756))
- [Inductor][CPP] Add transposed B matrix support for CppMicroGemmFP32Vec ([#147068](https://github.com/pytorch/pytorch/pull/147068))
- [Inductor][CPP] Fix the vec codegen for tanh ([#148254](https://github.com/pytorch/pytorch/pull/148254))
- [Inductor][CPP] Avoid transpose with cpp micro-gemm for FlexAttention ([#147069](https://github.com/pytorch/pytorch/pull/147069))
- [Inductor-CPP] If all of the activation scale dims are 1, make it a 0D tensor ([#147033](https://github.com/pytorch/pytorch/pull/147033))
- [Inductor] Hot fix after #148011 ([#148270](https://github.com/pytorch/pytorch/pull/148270))
- Add support for no-op concat with padded output ([#146866](https://github.com/pytorch/pytorch/pull/146866))
- [Intel GPU] Enable SDPA on XPU ([#147614](https://github.com/pytorch/pytorch/pull/147614))
- Updates to build rowwise scaled mm kernel on SM10.0a ([#148274](https://github.com/pytorch/pytorch/pull/148274))
- [inductor][triton] Fix average pool nd for int64 dtype ([#146061](https://github.com/pytorch/pytorch/pull/146061))
- Add a couple config options to compiler bisector ([#148450](https://github.com/pytorch/pytorch/pull/148450))
- [inductor][cpu] Fix error with FlexibleLayout weights in  BMM ([#148188](https://github.com/pytorch/pytorch/pull/148188))
- [mm_logs][ez] dump tuned mm info at lowering stage ([#148363](https://github.com/pytorch/pytorch/pull/148363))
- [cutlass backend][BE] Fix two small things in cutlass backend standalone debugger ([#148493](https://github.com/pytorch/pytorch/pull/148493))
- [AOTI] Fix aot_inductor_package test errors ([#148279](https://github.com/pytorch/pytorch/pull/148279))
- Fix only logging ir_post_fusion with torch_compile_debug enabled ([#148499](https://github.com/pytorch/pytorch/pull/148499))
- Fix bug in AOTI lowering ([#148364](https://github.com/pytorch/pytorch/pull/148364))
- [AOTI] build CPU CPP kernels at O3, and all other code at O1 ([#148587](https://github.com/pytorch/pytorch/pull/148587))
- [inductor] use eager stride for custom op if no tags ([#148367](https://github.com/pytorch/pytorch/pull/148367))
- [inductor][ck] add kBatch_sweep to config.rocm ([#148223](https://github.com/pytorch/pytorch/pull/148223))
- [MTIA] Use "ieee" instead of "tf32" for MTIA's default precision in FlexAttention ([#148565](https://github.com/pytorch/pytorch/pull/148565))
- Clear triton kernels after parent make_launcher ([#148604](https://github.com/pytorch/pytorch/pull/148604))
- [Inductor][Triton] Fix test_autotune_inplace_kernel to work with newer Triton version ([#148595](https://github.com/pytorch/pytorch/pull/148595))
- cpp_wrapper: reduce memory usage by removing unneeded temporaries ([#147403](https://github.com/pytorch/pytorch/pull/147403))
- [mm_logs] follow up to add count info based on shape for inductor `aten.mm`s ([#148623](https://github.com/pytorch/pytorch/pull/148623))
- Add cpp wrapper skip to cudagraph logs ([#148700](https://github.com/pytorch/pytorch/pull/148700))
- [Intel GPU][pt2e] Enable quantized grouped convolution at XPU ([#148522](https://github.com/pytorch/pytorch/pull/148522))
- [mm_logs] enhance the printing for overview info ([#148716](https://github.com/pytorch/pytorch/pull/148716))
- Code Clean: Remove unnecessary code ([#148735](https://github.com/pytorch/pytorch/pull/148735))
- [XPU][Inductor] Update Intel triton for release 2.7. ([#147727](https://github.com/pytorch/pytorch/pull/147727))
- [Windows][Inductor][XPU] Unload triton pyd files to be able to remove them on Windows. ([#148323](https://github.com/pytorch/pytorch/pull/148323))
- Subprocess compile (attempt 2) ([#148635](https://github.com/pytorch/pytorch/pull/148635))
- [CI] [inductor] Add cu126 inductor jobs and move away cu124 ([#148612](https://github.com/pytorch/pytorch/pull/148612))
- use statically_known_true instead of guard_size_oblivious in pattern matcher ([#147557](https://github.com/pytorch/pytorch/pull/147557))
- Don't clear feedback_saver_fns after cache clear ([#148723](https://github.com/pytorch/pytorch/pull/148723))
- Do not crash when compiling quantized LORA models ([#148435](https://github.com/pytorch/pytorch/pull/148435))
- [Upstream] Wrap log_2_e in tl.constexpr for new 3.3 bump ([#148785](https://github.com/pytorch/pytorch/pull/148785))
- [Triton 3.3] Remove ROCm specific mm gemm template ([#148662](https://github.com/pytorch/pytorch/pull/148662))
- [AOTI] Swith to local cpp compile for fbcode ([#148592](https://github.com/pytorch/pytorch/pull/148592))
- [inductor][triton] Block ptr analysis fix assert on matched index expression  ([#148446](https://github.com/pytorch/pytorch/pull/148446))
- [Inductor][Windows] add env_var switch to turn all Windows inductor UTs. ([#148733](https://github.com/pytorch/pytorch/pull/148733))
- codecache.py: use str.format rather than % formatting ([#148691](https://github.com/pytorch/pytorch/pull/148691))
- [pytorch] Update flexattention bwd config generation ([#148600](https://github.com/pytorch/pytorch/pull/148600))
- [Flex Attention] support num_heads > 1 in block_mask ([#148857](https://github.com/pytorch/pytorch/pull/148857))
- [MM] Add sm carevout to lowerings ([#148793](https://github.com/pytorch/pytorch/pull/148793))
- Update the comment ([#148726](https://github.com/pytorch/pytorch/pull/148726))
- Don't look at TESTING_ONLY in fuzzer ([#146870](https://github.com/pytorch/pytorch/pull/146870))
- [triton 3.3] Forward-fix mm template selection logic ([#148924](https://github.com/pytorch/pytorch/pull/148924))
### security
